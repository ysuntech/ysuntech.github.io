<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>汇编吾信</title>
    <link>http://tech.mwq365.cn/</link>
    <description>Recent content on 汇编吾信</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-CN</language>
    <lastBuildDate>Sat, 21 Oct 2017 04:00:00 +0800</lastBuildDate>
    
	<atom:link href="http://tech.mwq365.cn/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Airflow调度系统教程【二】:分布式和常见问题</title>
      <link>http://tech.mwq365.cn/data/airflow-tutorial-2/</link>
      <pubDate>Sat, 21 Oct 2017 04:00:00 +0800</pubDate>
      
      <guid>http://tech.mwq365.cn/data/airflow-tutorial-2/</guid>
      <description> 介绍 这是Airflow调度系统系列文章中的第二篇，主要介绍airflow调度系统的分布式设置和一些常见问题。 在大数据统计工作中，我们有一系列的程序任务需要运行。这些任务运行时间长，任务之间往往存在依赖关系，再加上任务运行的系统环境稳定性较差，导致数据结果要么不能按时生成，要么生成的数据结果不正确。而且每次出现故障后，手动修复数据的效率低下。
直到引入Airflow调度系统，这些问题都得到了较好的解决。Airflow对任务之间的依赖关系支持非常好。分布式部署更能提高任务处理效率和系统可用性。
核心概念 首先了解下Airflow中的几个核心概念:
 DAG: 字面意思为&amp;rdquo;有向无环图&amp;rdquo;，在Airflow里指任务流程图。 通过Python代码的方式定义任务和任务间的依赖关系。这些任务组成一个&amp;rdquo;有向无环图&amp;rdquo; Operator: Operator是关于任务如何执行的定义。Operator实例化后成为Task，在DAG里对应一个节点。节点之间的连线代表任务间的依赖关系。用得比较读的Operator主要是BashOperator
 Sensor: 探测器，有些任务需要一些前置条件，比如是否到了某个时间，比如某个接口响应是否正常。Sensor可以用来检测是否满足条件。Sensor是特殊的Operator。
 Tasks: Operator实例化之后就是Task, Task代表流程图中的一个节点-一个需要运行的任务。
 调度器(scheduler): 调度器负责读任务配置和检查任务是否满足运行条件，如果准备好，将任务送入队列。等待executor执行。
 执行器(executor): 从队列中拉取任务，执行，然后将结果写回响应队列。
 Web服务器(webserver)： 提供web界面，一般和Scheduler同时部署。在web界面上可禁用流程图，管理任务，查看任务运行日志等。
  分布式 Airflow默认配置下，调度和任务执行只能在单机运行。为了避免单点故障，提高系统的可用性和运行效率，我们将系统改造为分布式。 Airflow系统只需稍加配置，即可实现分布式调度。 首先需要将executor改为CeleryExecutor. 其次配置好Celery的backend。
常见问题 常见问题主要有这么几种： - 任务没有运行 可能是时间还没到。 注意，Airlfow DAG定义的startdate实际上是数据时间。对于一个startdate是2017-10-21 10:00:00，间隔为1天的任务来说，可能过了2017-10-21 11点，任务还没运行。实际上要等到10-22日10点，这个任务才能运行。按天统计任务一般都跑昨天的数据，这个概念倒也能理解。 也可能是这个任务依赖的其它任务尚未完成。 DAG定义代码有问题，导致DAG读取错误，无法运行。这个问题，注意个看错误提示就好。 任务没有运行，还有一种可能是调度系统任务队列满了。同时运行的DAG和Task数目都是有限制的。一但达到上限，就绪态的任务也只能等待。
 如何让一套调度系统给多个业务线使用 每个业务线使用单独的队列key即可。  </description>
    </item>
    
    <item>
      <title>使用hugo搭建博客系统</title>
      <link>http://tech.mwq365.cn/web/blog-with-hugo/</link>
      <pubDate>Fri, 20 Oct 2017 17:43:56 +0800</pubDate>
      
      <guid>http://tech.mwq365.cn/web/blog-with-hugo/</guid>
      <description>介绍 作为web技术从业人员，经常有一些笔记心得需要记录。可以选择在csdn或者oschina等站点写博客。也有人购买VPS，用wordpress搭建自己的博客。这样比较自由，但购买VPS，搭建lamp环境需要一定的Time和Money。其实有更简单的解决方案：使用hugo和github pages搭建全静态免费博客。
搭建博客 让我们开始吧,按步骤来：
 下载hugo软件，图省事可以直接下载二进制版本
 将下载得到的hugo二进制文件加入PATH环境变量。这样我们可以从命令行输入&amp;rdquo;hugo&amp;rdquo;随时调用hugo
 初始化博客项目
cd ~ # 创建名为hugo_blog的博客站点 hugo new site hugo_blog  设置主题，配置站点
cd hugo_blog/themes # 这里我们使用beg 主题 git clone https://github.com/dim0627/hugo_theme_beg.git beg # 修改配置文件 vim hugo_blog/config.toml  修改内容
languageCode = &amp;quot;zh-CN&amp;quot; baseurl = &amp;quot;https://mytestaccout.github.io/&amp;quot; title = &amp;quot;我的博客小站&amp;quot; theme = &amp;quot;beg&amp;quot; #googleAnalytics = &amp;quot;UA-XXXXXXXX-XX&amp;quot; # Optional #disqusShortname = &amp;quot;XYW&amp;quot; [params] dateformat = &amp;quot;Jan 2, 2006&amp;quot; # Optional  其中mytestaccout需要替换为自己的github账号
 写一篇博客
hugo new mydir/post1.</description>
    </item>
    
    <item>
      <title>Airflow调度系统教程【一】:安装</title>
      <link>http://tech.mwq365.cn/data/airflow-tutorial-1/</link>
      <pubDate>Fri, 20 Oct 2017 13:40:18 +0800</pubDate>
      
      <guid>http://tech.mwq365.cn/data/airflow-tutorial-1/</guid>
      <description>介绍 Airflow是一套开源任务调度系统，可以完善地处理任务之间的依赖关系，界面美观，操作方便，可扩展性较强。
这是Airflow调度系统系列文章中的第一篇，主要介绍环境搭建,插件安装和简单设置。
特点  Airflow是一个通用型任务调度系统，使用Python编写 任务调度使用Python代码定义，比较灵活； 支持任务间的依赖关系； 支持多种调度策略，包括分布式调度(通过Celery实现)； 自带较为美观的Web UI，操作方便。 自带日志查看，任务监控等常见功能； 注意：不能替代crontab，管理数据分析任务脚本以及其它cron任务。  安装 需要python2.7 以上版本，建议使用pip安装；使用virtualenv建立隔离环境。
 先安装Python2.7。如果没有特权账号，可下载anaconda2发行版安装。 然后下载setuptools,安装easy_install：https://pypi.python.org/pypi/setuptools 安装MySQL-Python包  yum install mysql-devel.x86_64 wget --no-check-certificate -c https://sourceforge.net/projects/mysql-python/files/mysql-python/1.2.3/MySQL-python-1.2.3.tar.gz/download mv download MySQL-python-1.2.3.tgz tar xvzf MySQL-python-1.2.3.tgz cd MySQL-python-1.2.3 python setup.py install   安装pip  wget -c --no-check-certificate https://bootstrap.pypa.io/get-pip.py export http_proxy=proxy.example.net:8080 export https_proxy=proxy.example.net:8080 python2.7 get-pip.py   安装virtualenv  pip2.7 install virtualenv   创建单独的python2.7环境  su adam cd mkdir pythonenvs cd pythonenvs virtualenv -p /usr/local/bin/python2.</description>
    </item>
    
  </channel>
</rss>